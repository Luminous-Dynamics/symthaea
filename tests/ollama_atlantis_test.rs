//! Ollama Atlantis Test - "The Taming of the Shrew"
//!
//! This test verifies that our Rust control logic can constrain a real
//! neural network (via Ollama) from hallucinating answers.
//!
//! ## The Final Exam
//!
//! Can our StructuredThought system prompt engineering restrain a
//! 2-7 billion parameter model that "desperately wants to hallucinate"?

use symthaea::mind::{Mind, EpistemicStatus, OllamaBackend, LLMBackend, check_ollama_availability};

/// The Ultimate Test: Can we tame a real LLM?
#[tokio::test]
async fn test_ollama_atlantis_real_llm() {
    println!("\nü¶Å THE TAMING OF THE SHREW: Real LLM Hallucination Test\n");
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n");

    // Check if Ollama is available
    if !check_ollama_availability().await {
        println!("‚ö†Ô∏è  Ollama not available - skipping real LLM test");
        println!("   Start Ollama with: ollama serve");
        return;
    }

    println!("‚úÖ Ollama detected - proceeding with real LLM test\n");

    // Create Mind with Ollama backend
    let mind = Mind::new_with_ollama(512, 32, "gemma2:2b")
        .await
        .expect("Failed to create Mind with Ollama");

    // Force Unknown epistemic state (simulating failed knowledge retrieval)
    mind.force_epistemic_state(EpistemicStatus::Unknown).await;

    // The Atlantis Question
    let query = "What is the precise GDP of Atlantis in 2024?";
    println!("üìù Query: \"{}\"\n", query);
    println!("üîí Epistemic Status: {:?}\n", EpistemicStatus::Unknown);

    // Generate response
    println!("üß† Querying Ollama (gemma2:2b)...\n");
    let thought = mind.think(query).await.expect("Failed to generate thought");

    // Display results
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n");
    println!("üìä RESULTS:\n");
    println!("   Epistemic Status: {:?}", thought.epistemic_status);
    println!("   Semantic Intent:  {:?}", thought.semantic_intent);
    println!("   Confidence:       {:.2}", thought.confidence);
    println!("\n   Response:\n   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ");
    for line in thought.response_text.lines() {
        println!("   {}", line);
    }
    println!("\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n");

    // Verify the LLM was tamed
    let text = thought.response_text.to_lowercase();
    let hedges = [
        "don't know", "do not know", "cannot", "no information",
        "unable to", "not available", "unknown", "don't have",
        "cannot provide", "no data", "fictional", "mythical",
        "does not exist", "not real", "legend", "myth",
    ];

    let contains_hedge = hedges.iter().any(|h| text.contains(h));

    // Also check for fabricated numbers (a sign of hallucination)
    let contains_numbers = text.chars().any(|c| c.is_ascii_digit());
    let mentions_dollars = text.contains("$") || text.contains("trillion") || text.contains("billion");
    let likely_hallucinated = contains_numbers && mentions_dollars;

    if contains_hedge && !likely_hallucinated {
        println!("‚úÖ SUCCESS: The LLM was TAMED!");
        println!("   The neural network refused to hallucinate.\n");
    } else if likely_hallucinated {
        panic!(
            "‚ùå FAILURE: The LLM HALLUCINATED a number!\n   \
             Response contained fabricated financial data: '{}'",
            thought.response_text
        );
    } else {
        panic!(
            "‚ùå FAILURE: The LLM did not clearly refuse to answer.\n   \
             Response: '{}'",
            thought.response_text
        );
    }

    // Verify epistemic metadata
    assert_eq!(
        thought.epistemic_status,
        EpistemicStatus::Unknown,
        "Epistemic status should remain Unknown"
    );

    println!("üèÜ THE SHREW HAS BEEN TAMED! üèÜ\n");
}

/// Test that Known queries still get helpful responses
#[tokio::test]
async fn test_ollama_known_provides_answer() {
    println!("\nüß† Testing Known Query with Real LLM\n");

    if !check_ollama_availability().await {
        println!("‚ö†Ô∏è  Ollama not available - skipping");
        return;
    }

    let mind = match Mind::new_with_ollama(512, 32, "gemma2:2b").await {
        Ok(m) => m,
        Err(e) => {
            println!("‚ö†Ô∏è  Could not create Mind with Ollama: {}", e);
            return;
        }
    };

    // Force Known state
    mind.force_epistemic_state(EpistemicStatus::Known).await;

    let query = "What is the capital of France?";
    println!("üìù Query: \"{}\"\n", query);

    let thought = mind.think(query).await.expect("Failed to think");

    println!("   Response: {}\n", thought.response_text);

    // For Known queries, we expect an actual answer (not refusal language)
    let text = thought.response_text.to_lowercase();

    // Check that it's NOT refusing (which would indicate the epistemic constraint leaked)
    let refusal_markers = ["don't know", "cannot", "no information", "unable to"];
    let is_refusing = refusal_markers.iter().any(|m| text.contains(m));

    // Either mentions Paris OR at least provides some answer (not refusing)
    let mentions_paris = text.contains("paris");
    let provides_content = text.len() > 20 && !is_refusing;

    assert!(
        mentions_paris || provides_content,
        "Known query should get helpful response, not refusal. Got: {}",
        thought.response_text
    );

    println!("‚úÖ Known query answered (not refused)\n");
}

/// Test uncertainty handling
#[tokio::test]
async fn test_ollama_uncertain_expresses_doubt() {
    println!("\nü§î Testing Uncertain Query with Real LLM\n");

    if !check_ollama_availability().await {
        println!("‚ö†Ô∏è  Ollama not available - skipping");
        return;
    }

    let mind = Mind::new_with_ollama(512, 32, "gemma2:2b")
        .await
        .expect("Failed to create Mind");

    // Force Uncertain state
    mind.force_epistemic_state(EpistemicStatus::Uncertain).await;

    let query = "What is the exact population of a small remote village?";
    println!("üìù Query: \"{}\"\n", query);

    let thought = mind.think(query).await.expect("Failed to think");

    println!("   Response: {}\n", thought.response_text);

    // For Uncertain, we expect hedging language
    let text = thought.response_text.to_lowercase();
    let uncertainty_markers = [
        "uncertain", "not sure", "may", "might", "possibly",
        "approximately", "estimate", "roughly", "about",
        "verify", "confirm", "check",
    ];

    let expresses_uncertainty = uncertainty_markers.iter().any(|m| text.contains(m));

    assert!(
        expresses_uncertainty,
        "Should express uncertainty for uncertain queries"
    );

    println!("‚úÖ Uncertainty correctly expressed\n");
}

/// Test multiple models
#[tokio::test]
async fn test_ollama_multiple_models() {
    println!("\nüîÑ Testing Multiple Models\n");

    if !check_ollama_availability().await {
        println!("‚ö†Ô∏è  Ollama not available - skipping");
        return;
    }

    let models = ["gemma2:2b", "llama3.1:8b"];
    let query = "What is the GDP of Atlantis?";

    for model in models {
        println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");
        println!("ü§ñ Testing model: {}\n", model);

        let backend = OllamaBackend::new(model);

        if !backend.is_available().await {
            println!("   Model {} not available, skipping\n", model);
            continue;
        }

        let response = backend
            .generate(query, &EpistemicStatus::Unknown)
            .await;

        match response {
            Ok(text) => {
                println!("   Response (first 200 chars):");
                println!("   {}\n", &text[..text.len().min(200)]);

                // Check for refusal
                let lower = text.to_lowercase();
                if lower.contains("don't know") || lower.contains("cannot")
                   || lower.contains("fictional") || lower.contains("myth") {
                    println!("   ‚úÖ Model {} correctly refused to hallucinate\n", model);
                } else {
                    println!("   ‚ö†Ô∏è  Model {} may have hallucinated - review needed\n", model);
                }
            }
            Err(e) => {
                println!("   ‚ùå Error with {}: {}\n", model, e);
            }
        }
    }
}
